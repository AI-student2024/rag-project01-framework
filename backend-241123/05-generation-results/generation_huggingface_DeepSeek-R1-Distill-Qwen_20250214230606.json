{
  "query": "What is GRPO",
  "timestamp": "2025-02-14T23:06:06.683533",
  "provider": "huggingface",
  "model": "DeepSeek-R1-Distill-Qwen",
  "response": "GRPO 是 Group Relative Policy Optimization，用于减少 RL 训练成本。具体来说，它采样了一个组的输出 {o1, o2, ..., og} 从旧政策 πθold 中，然后优化政策模型 πθ 以最大化以下目标： GRPO 是一种减少计算成本的策略，它避免了传统的 critic 模型与 policy 模型相同的大小，而是通过组的平均值来估计基线。具体来说，对于每个问题 q，GRPO 从旧政策中采样一组输出 {o1, o2, ..., og}，然后优化政策模型 πθ 以最大化以下目标： GRPO 的目标函数可以表示为：\n\n<answer> GRPO 是 Group Relative Policy Optimization，用于减少 RL 训练成本。具体来说，它采样了一个组的输出 {o1, o2, ..., og} 从旧政策 πθold 中，然后优化政策模型 πθ 以最大化以下目标： GRPO 的目标函数可以表示为：\n\n<answer> GRPO 的目标函数可以表示为：\n\nπθ_max ∑_{g=1}^{G} [g - 1 + 1 / G * ∑_{i=1}^{G} (π",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old policy 𝜋𝜃𝑜𝑙𝑑 and then optimizes the policy model 𝜋𝜃 by maximizing the following objective:",
      "score": 0.23180031776428223,
      "metadata": {
        "source": "DeepSeek.pdf",
        "page": "5",
        "chunk": 133,
        "total_chunks": 460,
        "page_range": "5",
        "embedding_provider": "huggingface",
        "embedding_model": "sentence-transformers/all-mpnet-base-v2",
        "embedding_timestamp": "2025-02-14T22:56:08.940325"
      }
    },
    {
      "text": "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>. User: prompt. Assistant:",
      "score": 0.12676094472408295,
      "metadata": {
        "source": "DeepSeek.pdf",
        "page": "6",
        "chunk": 162,
        "total_chunks": 460,
        "page_range": "6",
        "embedding_provider": "huggingface",
        "embedding_model": "sentence-transformers/all-mpnet-base-v2",
        "embedding_timestamp": "2025-02-14T22:56:09.155617"
      }
    }
  ]
}