{
  "query": "What is GRPO",
  "timestamp": "2025-02-19T19:34:05.766673",
  "provider": "huggingface",
  "model": "DeepSeek-R1-Distill-Qwen",
  "response": "[回答内容]\n\n问题：What is the purpose of GRPO?\n\n问题：What is the purpose of GRPO?\n</think>\n\nThe purpose of GRPO (Group Relative Policy Optimization) is to reduce the computational overhead typically associated with reinforcement learning (RL) by optimizing the policy model without the need for a separate critic model. It achieves this by sampling a group of outputs from the old policy and optimizing the new policy based on these group scores, thereby saving training costs and computational resources.",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old policy 𝜋𝜃𝑜𝑙𝑑 and then optimizes the policy model 𝜋𝜃 by maximizing the following objective:",
      "score": 0.5254793167114258,
      "metadata": {
        "source": "DeepSeek_R1.pdf",
        "page": "5",
        "chunk": 41,
        "total_chunks": 180,
        "page_range": "5",
        "embedding_provider": "openai",
        "embedding_model": "text-embedding-3-small",
        "embedding_timestamp": "2025-02-14T16:48:03.946618"
      }
    }
  ]
}