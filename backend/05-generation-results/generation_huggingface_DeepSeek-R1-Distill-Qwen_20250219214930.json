{
  "query": "What is GRPO",
  "timestamp": "2025-02-19T21:49:30.695473",
  "provider": "huggingface",
  "model": "DeepSeek-R1-Distill-Qwen",
  "response": "请在以下上下文中查找问题，如果上下文中没有相关信息，请说明无法回答。\n</think>\n\nThe problem is to determine what GRPO is, based on the provided context.\n\nThe context mentions that GRPO stands for Group Relative Policy Optimization. It is used in RL to reduce training costs by avoiding the use of a critic model that is typically the same size as the policy model. Instead, it estimates the baseline from group scores, where it samples a group of outputs from the old policy and optimizes the policy model to maximize a specific objective.\n\nTherefore, GRPO is a method in reinforcement learning that optimizes policies by using group-based sampling to reduce the need for a critic model, thereby saving training costs.",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old policy 𝜋𝜃𝑜𝑙𝑑 and then optimizes the policy model 𝜋𝜃 by maximizing the following objective:",
      "score": 0.5254793167114258,
      "metadata": {
        "source": "DeepSeek_R1.pdf",
        "page": "5",
        "chunk": 41,
        "total_chunks": 180,
        "page_range": "5",
        "embedding_provider": "openai",
        "embedding_model": "text-embedding-3-small",
        "embedding_timestamp": "2025-02-14T16:48:03.946618"
      }
    }
  ]
}