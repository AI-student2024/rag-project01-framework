{
  "query": "What is GRPO",
  "timestamp": "2025-02-18T14:44:42.284558",
  "provider": "huggingface",
  "model": "DeepSeek-R1-Distill-Qwen",
  "response": "（请用中文回答）\n</think>\n\nTo determine the exact meaning of \"GRPO\" (Group Relative Policy Optimization), we need to examine the provided context:\n\n1. **Source 1**: \"Group Relative Policy Optimization\" is mentioned.\n2. **Details**:\n   - **Objective**: The paper discusses Group Relative Policy Optimization (GRPO), which aims to reduce training costs in reinforcement learning (RL).\n   - **Key Features**:\n     - **Policy vs. Critic Model**: GRPO avoids the typically large critic model size of the policy model.\n     - **Baseline Estimation**: GRPO estimates the baseline from group scores instead of relying on the critic model.\n     - **Optimization Objective**: For each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old policy 𝜋𝜃𝑜𝑙𝑑, and then optimizes the policy model 𝜋𝜃 by maximizing the following objective.\n\nSince the term \"GRPO\" is used in the context of Group Relative Policy Optimization and it is defined in the provided source, we can conclude that GRPO refers to this specific optimization method in reinforcement learning.\n\nAnswer: GRPO stands for Group Relative Policy Optimization, which is a method in reinforcement learning that aims to reduce training costs by optimizing the policy model without relying on a large critic model and estimating the baseline from group scores.",
  "context": [
    {
      "text": "Group Relative Policy Optimization In order to save the training costs of RL, we adopt Group Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is typically the same size as the policy model, and estimates the baseline from group scores instead. Specifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old policy 𝜋𝜃𝑜𝑙𝑑 and then optimizes the policy model 𝜋𝜃 by maximizing the following objective:",
      "score": 0.5254793167114258,
      "metadata": {
        "source": "DeepSeek_R1.pdf",
        "page": "5",
        "chunk": 41,
        "total_chunks": 180,
        "page_range": "5",
        "embedding_provider": "openai",
        "embedding_model": "text-embedding-3-small",
        "embedding_timestamp": "2025-02-14T16:48:03.946618"
      }
    }
  ]
}